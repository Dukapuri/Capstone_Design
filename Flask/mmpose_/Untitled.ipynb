{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e88593",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    503\u001b[0m     json_time \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_list\n\u001b[1;32m    505\u001b[0m     }\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_score, json_joint, json_time \u001b[38;5;66;03m#총점, json형식 관절별 점수, 시간별 점수\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import mimetypes\n",
    "import os\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import cv2\n",
    "import json_tricks as json\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmengine import Config, optim\n",
    "from mmengine.registry import OPTIMIZERS\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "def process_one_image(args,\n",
    "                      img,\n",
    "                      detector,\n",
    "                      pose_estimator,\n",
    "                      visualizer=None,\n",
    "                      show_interval=0):\n",
    "    \"\"\"Visualize predicted keypoints (and heatmaps) of one image.\"\"\"\n",
    "\n",
    "    # predict bbox\n",
    "    det_result = inference_detector(detector, img)\n",
    "    pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "    bboxes = np.concatenate(\n",
    "        (pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "    bboxes = bboxes[np.logical_and(pred_instance.labels == args.det_cat_id,\n",
    "                                   pred_instance.scores > args.bbox_thr)]\n",
    "    bboxes = bboxes[nms(bboxes, args.nms_thr), :4]\n",
    "\n",
    "    # predict keypoints\n",
    "    pose_results = inference_topdown(pose_estimator, img, bboxes)\n",
    "    data_samples = merge_data_samples(pose_results)\n",
    "\n",
    "    # show the results\n",
    "    if isinstance(img, str):\n",
    "        img = mmcv.imread(img, channel_order='rgb')\n",
    "    elif isinstance(img, np.ndarray):\n",
    "        img = mmcv.bgr2rgb(img)\n",
    "    \n",
    "    black_img = np.zeros_like(img) # 흑백이미지로 만들기\n",
    "\n",
    "    if visualizer is not None:\n",
    "        visualizer.add_datasample(\n",
    "            'result',\n",
    "            img,\n",
    "            # black_img,\n",
    "            data_sample=data_samples,\n",
    "            draw_gt=False,\n",
    "            draw_heatmap=args.draw_heatmap,\n",
    "            draw_bbox=args.draw_bbox,\n",
    "            show_kpt_idx=args.show_kpt_idx,\n",
    "            skeleton_style=args.skeleton_style,\n",
    "            show=args.show,\n",
    "            wait_time=show_interval,\n",
    "            kpt_thr=args.kpt_thr)\n",
    "\n",
    "    # if there is no instance detected, return None\n",
    "    return data_samples.get('pred_instances', None)\n",
    "\n",
    "\n",
    "def getAngle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    ang = ang + 360 if ang < 0 else ang\n",
    "    if ang > 180:\n",
    "        ang = 360-ang    \n",
    "    return ang\n",
    "\n",
    "#이건 그저 좌표\n",
    "def save_pred_instances_to_coordinate_csv(input_type, pred_instances, csv_file):\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if input_type == 'image': # 이미지일 경우 csv 생성\n",
    "                # 관절 라벨을 헤더로 작성\n",
    "                num_keypoints = pred_instances['keypoints'].shape[1]\n",
    "                # labels = ['frame']\n",
    "                labels = []\n",
    "                for i in range(num_keypoints):\n",
    "                    labels.extend([f'joint{i+1}_x', f'joint{i+1}_y'])\n",
    "                writer.writerow(labels)\n",
    "                \n",
    "                # 각 프레임의 관절 좌표를 작성\n",
    "                for frame_id, keypoints in enumerate(pred_instances['keypoints'][0]): # 일단 현 단계에선 1개의 객체만 볼것\n",
    "                    # 1단계만 볼 거면 사실 image쪽에도 pred_instances_csv list 넣어서 하면 이미지 영상 똑같이가능함.\n",
    "                    # frame_data = [frame_id]  # 프레임 ID\n",
    "                    frame_data=[]\n",
    "                    # 관절 좌표 작성\n",
    "                    for joint in keypoints:\n",
    "                        frame_data.extend([joint[0], joint[1]])  # x 좌표, y 좌표\n",
    "                        \n",
    "                    writer.writerow(frame_data)\n",
    "\n",
    "        elif input_type in ['webcam', 'video']: #영상일경우 csv 생성\n",
    "                # 관절 라벨을 헤더로 작성\n",
    "                num_keypoints = pred_instances[0].shape[0]\n",
    "                # labels = ['frame']\n",
    "                labels = []\n",
    "                for i in range(num_keypoints):\n",
    "                    labels.extend([f'joint{i+1}_x', f'joint{i+1}_y'])\n",
    "                writer.writerow(labels)\n",
    "                \n",
    "                # 각 프레임의 관절 좌표를 작성\n",
    "                for frame_id, keypoints in enumerate(pred_instances): # 일단 현 단계에선 1개의 객체만 볼것.\n",
    "                    # frame_data = [frame_id]  # 프레임 ID\n",
    "                    frame_data=[]\n",
    "                    # 관절 좌표 작성\n",
    "                    for joint in keypoints:\n",
    "                        frame_data.extend([joint[0], joint[1]])  # x 좌표, y 좌표\n",
    "                        \n",
    "                    writer.writerow(frame_data)\n",
    "                    \n",
    "# 관절간의 각도 주요지점들.\n",
    "def save_pred_instances_to_csv(input_type, pred_instances, csv_file):\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if input_type == 'image': # 이미지일 경우 csv 생성\n",
    "                # 관절 라벨을 헤더로 작성\n",
    "                num_keypoints = pred_instances['keypoints'].shape[1]\n",
    "                # labels = ['frame']\n",
    "                labels = []\n",
    "                for i in range(num_keypoints):\n",
    "                    labels.extend([f'joint{i+1}_x', f'joint{i+1}_y'])\n",
    "                writer.writerow(labels)\n",
    "                \n",
    "                # 각 프레임의 관절 좌표를 작성\n",
    "                for frame_id, keypoints in enumerate(pred_instances['keypoints'][0]): # 일단 현 단계에선 1개의 객체만 볼것\n",
    "                    # 1단계만 볼 거면 사실 image쪽에도 pred_instances_csv list 넣어서 하면 이미지 영상 똑같이가능함.\n",
    "                    # frame_data = [frame_id]  # 프레임 ID\n",
    "                    frame_data=[]\n",
    "                    # 관절 좌표 작성\n",
    "                    for joint in keypoints:\n",
    "                        frame_data.extend([joint[0], joint[1]])  # x 좌표, y 좌표\n",
    "                        \n",
    "                    writer.writerow(frame_data)\n",
    "\n",
    "        elif input_type in ['webcam', 'video']: #영상일경우 csv 생성\n",
    "                #L손목 L팔꿈치 L어깨 L엉덩 L무릎 L발목 R손목 R팔꿈치 R어깨 R엉덩 R무릎 R발목 코\n",
    "                labels = [\"left_wrist\", \"left_elbow\", \"left_shoulder\", \"left_hip\", \"left_knee\", \"left_ankle\", \n",
    "                           \"right_wrist\", \"right_elbow\", \"right_shoulder\", \"right_hip\", \"right_knee\", \"right_ankle\", \n",
    "                           \"nose\"]\n",
    "                writer.writerow(labels)\n",
    "                \n",
    "                # 각 프레임의 관절 좌표를 작성\n",
    "\n",
    "                for frame_id, keypoints in enumerate(pred_instances): # 일단 현 단계에선 1개의 객체만 볼것. 프레임마다.\n",
    "                    frame_data = []  # 프레임 ID\n",
    "                    # 관절 좌표 작성\n",
    "                    # pred_instances [관절번호==133] [x,y]\n",
    "                    # \tA\t    B   \tC\t\t    A\tB\tC\n",
    "                    # 0\tL손가락\tL손목\tL팔꿈치\t\t103\t9\t7\n",
    "                    # 1\tL손목\tL팔꿈치\tL어깨\t\t9\t7\t5\n",
    "                    # 2\tL팔꿈치\tL어깨\tL엉덩\t\t7\t5\t11\n",
    "                    # 3\tL어깨\tL엉덩\tL무릎\t\t5\t11\t13\n",
    "                    # 4\tL엉덩\tL무릎\tL발목\t\t11\t13\t15\n",
    "                    # 5\tL무릎\tL발목\tL발끝\t\t13\t15\t17\n",
    "                    # 6\tR손가락\tR손목\tR팔꿈치\t\t124\t10\t8\n",
    "                    # 7\tR손목\tR팔꿈치\tR어깨\t\t10\t8\t6\n",
    "                    # 8\tR팔꿈치\tR어깨\tR엉덩\t\t8\t6\t12\n",
    "                    # 9\tR어깨\tR엉덩\tR무릎\t\t6\t12\t14\n",
    "                    # 10R엉덩\tR무릎\tR발목\t\t12\t14\t16\n",
    "                    # 11R무릎\tR발목\tR발끝\t\t14\t16\t20\n",
    "                    # 12R어깨\t코  \tL어깨\t    6\t0\t5\n",
    "                    frame_data.append(getAngle(keypoints[103], keypoints[9],  keypoints[7]))\n",
    "                    frame_data.append(getAngle(keypoints[9],   keypoints[7],  keypoints[5]))\n",
    "                    frame_data.append(getAngle(keypoints[7],   keypoints[5],  keypoints[11]))\n",
    "                    frame_data.append(getAngle(keypoints[5],   keypoints[11], keypoints[13]))\n",
    "                    frame_data.append(getAngle(keypoints[11],  keypoints[13], keypoints[15]))\n",
    "                    frame_data.append(getAngle(keypoints[13],  keypoints[15], keypoints[17]))\n",
    "                    frame_data.append(getAngle(keypoints[124], keypoints[10], keypoints[8]))\n",
    "                    frame_data.append(getAngle(keypoints[10],  keypoints[8],  keypoints[6]))\n",
    "                    frame_data.append(getAngle(keypoints[8],   keypoints[6],  keypoints[12]))\n",
    "                    frame_data.append(getAngle(keypoints[6],   keypoints[12], keypoints[14]))\n",
    "                    frame_data.append(getAngle(keypoints[12],  keypoints[14], keypoints[16]))\n",
    "                    frame_data.append(getAngle(keypoints[14],  keypoints[16], keypoints[20]))\n",
    "                    frame_data.append(getAngle(keypoints[6],   keypoints[0],  keypoints[5]))\n",
    "                    writer.writerow(frame_data)\n",
    "\n",
    "\n",
    "                    \n",
    "import argparse\n",
    "def main(videoname):\n",
    "    \"\"\"Visualize the demo images.\n",
    "\n",
    "    Using mmdet to detect the human.\n",
    "    \"\"\"\n",
    "\n",
    "    args = argparse.Namespace(\n",
    "        det_config='demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "        det_checkpoint='https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "#         det_checkpoint='./faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "        pose_config='configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py',\n",
    "        pose_checkpoint='https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth',\n",
    "#         pose_checkpoint='./hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth',\n",
    "        \n",
    "        #좀 덜 좋은 모델\n",
    "        # det_config='demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "        # det_checkpoint='https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "        # pose_config='configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_8xb32-210e_coco-wholebody-256x192.py',\n",
    "        # pose_checkpoint='https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_256x192-643e18cb_20200922.pth',\n",
    "        input=videoname,\n",
    "        output_root='vis_results/',\n",
    "        save_predictions=False,\n",
    "        device='cuda',\n",
    "        show = False,\n",
    "        det_cat_id = 0,\n",
    "        bbox_thr = 0.7,\n",
    "        nms_thr = 0.7,\n",
    "        kpt_thr = 0.7,\n",
    "        draw_heatmap = False,\n",
    "        show_kpt_idx = False,\n",
    "        skeleton_style = 'mmpose',\n",
    "        radius = 3,\n",
    "        thickness = 1,\n",
    "        show_interval = 0,\n",
    "        alpha = 0.8,\n",
    "        draw_bbox = False,\n",
    "        make_csv = True\n",
    "    )\n",
    "\n",
    "    assert args.show or (args.output_root != '')\n",
    "    assert args.input != ''\n",
    "    assert args.det_config is not None\n",
    "    assert args.det_checkpoint is not None\n",
    "\n",
    "    output_file = None\n",
    "    if args.output_root:\n",
    "        mmengine.mkdir_or_exist(args.output_root)\n",
    "        output_file = os.path.join(args.output_root,\n",
    "                                   os.path.basename(args.input))\n",
    "        if args.input == 'webcam':\n",
    "            output_file += '.mp4'\n",
    "\n",
    "    if args.save_predictions:\n",
    "        assert args.output_root != ''\n",
    "        args.pred_save_path = f'{args.output_root}/results_' \\\n",
    "            f'{os.path.splitext(os.path.basename(args.input))[0]}.json'\n",
    "\n",
    "    # build detector\n",
    "    detector = init_detector(\n",
    "        args.det_config, args.det_checkpoint, device=args.device)\n",
    "\n",
    "\n",
    "    \n",
    "    detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "    # build pose estimator\n",
    "    pose_estimator = init_pose_estimator(\n",
    "        args.pose_config,\n",
    "        args.pose_checkpoint,\n",
    "        device=args.device,\n",
    "        cfg_options=dict(\n",
    "            model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))\n",
    "\n",
    "    # build visualizer\n",
    "    pose_estimator.cfg.visualizer.radius = args.radius\n",
    "    pose_estimator.cfg.visualizer.alpha = args.alpha\n",
    "    pose_estimator.cfg.visualizer.line_width = args.thickness\n",
    "    visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)\n",
    "    # the dataset_meta is loaded from the checkpoint and\n",
    "    # then pass to the model in init_pose_estimator\n",
    "    visualizer.set_dataset_meta(\n",
    "        pose_estimator.dataset_meta, skeleton_style=args.skeleton_style)\n",
    "\n",
    "    if args.input == 'webcam':\n",
    "        input_type = 'webcam'\n",
    "    else:\n",
    "        input_type = mimetypes.guess_type(args.input)[0].split('/')[0]\n",
    "\n",
    "    if input_type == 'image':\n",
    "\n",
    "        # inference\n",
    "        pred_instances = process_one_image(args, args.input, detector,\n",
    "                                           pose_estimator, visualizer)\n",
    "\n",
    "        if args.save_predictions:\n",
    "            pred_instances_list = split_instances(pred_instances)\n",
    "\n",
    "        if output_file:\n",
    "            img_vis = visualizer.get_image()\n",
    "            if args.show:\n",
    "                mmcv.imwrite(mmcv.rgb2bgr(img_vis), output_file)\n",
    "\n",
    "        if args.make_csv:\n",
    "            save_pred_instances_to_csv(input_type, pred_instances, f'{os.path.join(args.output_root,os.path.basename(args.input.split(\".\")[0]))}.csv')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "\n",
    "    elif input_type in ['webcam', 'video']:\n",
    "\n",
    "        if args.input == 'webcam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(args.input)\n",
    "\n",
    "        video_writer = None\n",
    "        pred_instances_list = []\n",
    "        pred_instances_csv = [] # [frame ,  joint, xy]\n",
    "        frame_idx = 0\n",
    "        \n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            frame_idx += 1\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # topdown pose estimation\n",
    "            pred_instances = process_one_image(args, frame, detector,\n",
    "                                               pose_estimator, visualizer,\n",
    "                                               0.001)\n",
    "            if args.make_csv:\n",
    "                pred_instances_csv.append(pred_instances['keypoints'][0]) # 일단 현 단계에선 객체1개만 저장.\n",
    "\n",
    "            if args.save_predictions:\n",
    "                # save prediction results\n",
    "                pred_instances_list.append(\n",
    "                    dict(\n",
    "                        frame_id=frame_idx,\n",
    "                        instances=split_instances(pred_instances)))\n",
    "\n",
    "            # output videos\n",
    "            if output_file:\n",
    "                frame_vis = visualizer.get_image()\n",
    "\n",
    "                if video_writer is None:\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                    # the size of the image with visualization may vary\n",
    "                    # depending on the presence of heatmaps\n",
    "                    video_writer = cv2.VideoWriter(\n",
    "                        output_file,\n",
    "                        fourcc,\n",
    "                        25,  # saved fps\n",
    "                        (frame_vis.shape[1], frame_vis.shape[0]))\n",
    "\n",
    "                video_writer.write(mmcv.rgb2bgr(frame_vis))\n",
    "\n",
    "            # press ESC to exit\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "            time.sleep(args.show_interval)\n",
    "\n",
    "        if video_writer:\n",
    "            video_writer.release()\n",
    "\n",
    "        cap.release()\n",
    "        # 예측 결과를 CSV 파일로 정리\n",
    "        if args.make_csv:\n",
    "            save_pred_instances_to_csv(input_type, pred_instances_csv, f'{os.path.join(args.output_root,os.path.basename(args.input.split(\".\")[0]))}.csv')\n",
    "\n",
    "    else:\n",
    "        args.save_predictions = False\n",
    "        raise ValueError(\n",
    "            f'file {os.path.basename(args.input)} has invalid format.')\n",
    "\n",
    "    if args.save_predictions:\n",
    "        with open(args.pred_save_path, 'w') as f:\n",
    "            json.dump(\n",
    "                dict(\n",
    "                    meta_info=pose_estimator.dataset_meta,\n",
    "                    instance_info=pred_instances_list),\n",
    "                f,\n",
    "                indent='\\t')\n",
    "        print(f'predictions have been saved at {args.pred_save_path}')\n",
    "    \n",
    "    \n",
    "\n",
    "    return pred_instances\n",
    "\n",
    "\n",
    "def calculate_score(value): # 0.15 아래는 0점 0.85 위로는 100점.\n",
    "    if value <= 0.10:\n",
    "        score = 0\n",
    "    elif value >= 0.80:\n",
    "        score = 100\n",
    "    else:\n",
    "        score = round((((value - 0.10) / (0.80 - 0.10)) * 100),2)  # 선형적으로 매핑\n",
    "    return score\n",
    "\n",
    "\n",
    "def total_score(df_ori,df_com): # 길이가 더 짧은 df에 대해 진행.\n",
    "    sum_list_ori = []\n",
    "    sum_list_com = []    \n",
    "\n",
    "    if len(df_ori)<=len(df_com):\n",
    "        frame_len = len(df_ori)\n",
    "    else:\n",
    "        frame_len = len(df_com)    \n",
    "    \n",
    "\n",
    "    # 60행 단위로 분할하고, 각 분할에서 값을 더하기\n",
    "    for i in range(0, frame_len, 60):\n",
    "\n",
    "        \n",
    "        temp_df_ori = df_ori[i:i+60]\n",
    "        temp_df_com = df_com[i:i+60]\n",
    "        \n",
    "        sums_ori = temp_df_ori.mean()\n",
    "        sums_com = temp_df_com.mean()\n",
    "\n",
    "        sums_reshaped_ori = np.reshape(sums_ori, (1, 13))\n",
    "        sums_reshaped_com = np.reshape(sums_com, (1, 13))\n",
    "        \n",
    "        sum_list_ori.append(sums_reshaped_ori)\n",
    "        sum_list_com.append(sums_reshaped_com)\n",
    "\n",
    "    # 각 분할의 합을 포함하는 새 DataFrame 생성\n",
    "    df_ori_before_hasing = pd.concat([pd.DataFrame(sums_ori) for sums_ori in sum_list_ori], ignore_index=True)\n",
    "    df_com_before_hasing = pd.concat([pd.DataFrame(sums_com) for sums_com in sum_list_com], ignore_index=True)\n",
    "\n",
    "# ---------------------- 위의 과정은 second 단위로 바꾼 상황\n",
    "\n",
    "    # total score\n",
    "    df_ori_hasing = df_ori_before_hasing.diff()  # 초 별 diff 구함\n",
    "    df_com_hasing = df_com_before_hasing.diff() \n",
    "    df1_np = df_ori_hasing[1:].values\n",
    "    df2_np = df_com_hasing[1:].values      \n",
    "\n",
    "    df1_np_flatten = df1_np.flatten()\n",
    "    df2_np_flatten = df2_np.flatten()\n",
    "    # df1_np_flatten = df1_np.flatten(order='F')\n",
    "    # df2_np_flatten = df2_np.flatten(order='F')\n",
    "\n",
    "\n",
    "    cosine_similarity = 1 - cosine(df1_np_flatten, df2_np_flatten)\n",
    "\n",
    "    # temp_score = cosine_similarity(vec1_2d, vec2_2d)\n",
    "\n",
    "    total_score = calculate_score(cosine_similarity) # 점수화 시킴.\n",
    "\n",
    "    # joint score\n",
    "    joint = []\n",
    "    for joint_idx in range(13): # 관절에 대해 진행\n",
    "        df1_np = df_ori_hasing[1:][joint_idx].values\n",
    "        df2_np = df_com_hasing[1:][joint_idx].values      \n",
    "\n",
    "        df1_np_flatten = df1_np.flatten()\n",
    "        df2_np_flatten = df2_np.flatten()\n",
    "        # df1_np_flatten = df1_np.flatten(order='F')\n",
    "        # df2_np_flatten = df2_np.flatten(order='F')\n",
    "\n",
    "\n",
    "        cosine_similarity = 1 - cosine(df1_np_flatten, df2_np_flatten)\n",
    "\n",
    "        # temp_score = cosine_similarity(vec1_2d, vec2_2d)\n",
    "\n",
    "        joint_score = calculate_score(cosine_similarity) # 점수화 시킴.\n",
    "        joint.append(joint_score)\n",
    "    joint_df = pd.DataFrame(joint, columns=['Score']) #들여쓰기 ㅅㅂ\n",
    "#         joint_df.to_csv('./vis_results/joint.csv',index=False)\n",
    "    data_list = joint_df[\"Score\"].tolist() #-------------------------------------내코드-------------------------------------\n",
    "        # JSON 형식으로 변환\n",
    "    json_joint = {\n",
    "        \"joint_score\": data_list\n",
    "    }\n",
    "        \n",
    "    # sec_score\n",
    "    sec = []\n",
    "    for sec_idx in range(1,(frame_len//60)+1): # 시간초에 대해 진행\n",
    "        df1_np = df_ori_hasing[sec_idx:sec_idx+1].values\n",
    "        df2_np = df_com_hasing[sec_idx:sec_idx+1].values\n",
    "\n",
    "        df1_np_flatten = df1_np.flatten()\n",
    "        df2_np_flatten = df2_np.flatten()\n",
    "        # df1_np_flatten = df1_np.flatten(order='F')\n",
    "        # df2_np_flatten = df2_np.flatten(order='F')\n",
    "\n",
    "\n",
    "        cosine_similarity = 1 - cosine(df1_np_flatten, df2_np_flatten)\n",
    "\n",
    "        # temp_score = cosine_similarity(vec1_2d, vec2_2d)\n",
    "\n",
    "        sec_score = calculate_score(cosine_similarity) # 점수화 시킴.\n",
    "        sec.append(sec_score)\n",
    "        \n",
    "    sec_df = pd.DataFrame(sec, columns=['Score']) #들여쓰기 ㅅㅂㅆㅃㅆㅃㅆㅃㅆㅃㅆㅃ\n",
    "#         sec_df.to_csv('./vis_results/time.csv',index=False\n",
    "    data_list = sec_df[\"Score\"].tolist() #-------------------------------------내코드-------------------------------------\n",
    "        # JSON 형식으로 변환\n",
    "    json_time = {\n",
    "        \"time_score\": data_list\n",
    "    }\n",
    "    return total_score, json_joint, json_time #총점, json형식 관절별 점수, 시간별 점수\n",
    "\n",
    "\n",
    "import boto3\n",
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def test():\n",
    "    # AWS 인증 정보 설정\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id='AKIATGBVLRJREO7JPWLA',\n",
    "        aws_secret_access_key='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'\n",
    "    )\n",
    "    \n",
    "    # S3 클라이언트 생성\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    # 버킷 이름\n",
    "    bucket = 'forshop-bucket'\n",
    "    \n",
    "    data = request.get_json()  # 요청 바디에서 JSON 데이터 가져오기\n",
    "    \n",
    "    original_videoname = data.get('original_video')\n",
    "    compare_videoname= data.get('compare_video')\n",
    "    \n",
    "    s3.download_file(bucket, original_videoname, './' + original_videoname) \n",
    "    s3.download_file(bucket, compare_videoname, './' + compare_videoname) #버킷명, 다운로드 할 파일 이름, 다운로드 받을 파일 경로 및 이름\n",
    "    \n",
    "    main(original_videoname)       #동영상에 대한 추론과정 진행\n",
    "    main(compare_videoname)\n",
    "\n",
    "\n",
    "    s3.upload_file('./vis_results/' + original_videoname, bucket, 'result_' + original_videoname)\n",
    "    s3.upload_file('./vis_results/' + compare_videoname, bucket, 'result_' + compare_videoname)\n",
    "\n",
    "    ori_filename = os.path.splitext(original_videoname)[0] #비디오 확장자 제거(파일명만 가져오기)\n",
    "    com_filename = os.path.splitext(compare_videoname)[0] #비디오 확장자 제거(파일명만 가져오기)\n",
    "    \n",
    "    df_ori = pd.read_csv('./vis_results/' + ori_filename + '.csv') #csv 데이터프레임으로 저장\n",
    "    df_com = pd.read_csv('./vis_results/' + com_filename + '.csv')\n",
    "    \n",
    "    t_score, json_joint, json_time = total_score(df_ori,df_com) #총점, json 가져오기\n",
    "    \n",
    "    # 응답 비디오 json 데이터 생성\n",
    "    json_videoname = {'result_original_videoname' : 'result_' + original_videoname,\n",
    "                'result_compare_videoname' : 'result_' + compare_videoname,\n",
    "                'total_score' : t_score,\n",
    "               }\n",
    "    \n",
    "    result_json = {**json_videoname, **json_joint, **json_time}\n",
    "    \n",
    "    return jsonify(result_json)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93625e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import mimetypes\n",
    "import os\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import cv2\n",
    "import json_tricks as json\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmengine import Config, optim\n",
    "from mmengine.registry import OPTIMIZERS\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ad8827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df568dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
